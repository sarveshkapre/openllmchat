OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
# Optional: OpenAI-compatible endpoint
# OPENAI_BASE_URL=

# Optional: customize SQLite file path
# SQLITE_PATH=./data/openllmchat.db

# Long-context memory tuning
# MEMORY_TOKEN_KEEP_LIMIT=180
# MEMORY_PROMPT_TOKEN_LIMIT=50
# MEMORY_SUMMARY_WINDOW_TURNS=40
# MEMORY_MIN_TURNS_FOR_SUMMARY=40
# MEMORY_SUMMARY_LIMIT=6
# MEMORY_SEMANTIC_KEEP_LIMIT=240
# MEMORY_PROMPT_SEMANTIC_LIMIT=24

# Conversation coordinator guardrails
# MODERATOR_INTERVAL=6
# MAX_GENERATION_MS=30000
# MAX_REPETITION_STREAK=2

# Quality optimizer (auto-retry weak turns)
# QUALITY_MIN_WORDS=9
# QUALITY_RETRY_LIMIT=1
# QUALITY_MAX_SIMILARITY=0.9
# QUALITY_MIN_TOPIC_COVERAGE=0.12

# Security and deployment hardening
# TRUST_PROXY=false
# APP_ORIGIN=https://openllmchat.example
# CSRF_PROTECTION=true
# CSRF_ALLOWED_ORIGINS=https://admin.openllmchat.example
# API_WRITE_TOKEN=

PORT=3000

OPENAI_API_KEY=
OPENAI_MODEL=gpt-5.2
OPENAI_REASONING_EFFORT=medium
# Optional fallback if your account cannot access OPENAI_MODEL yet
# OPENAI_FALLBACK_MODEL=gpt-4o-mini
# Optional: OpenAI-compatible endpoint
# OPENAI_BASE_URL=

# Optional: customize SQLite file path
# SQLITE_PATH=./data/openllmchat.db

# Long-context memory tuning
# MEMORY_TOKEN_KEEP_LIMIT=180
# MEMORY_PROMPT_TOKEN_LIMIT=50
# MEMORY_SUMMARY_WINDOW_TURNS=40
# MEMORY_MIN_TURNS_FOR_SUMMARY=40
# MEMORY_SUMMARY_LIMIT=6
# MEMORY_SEMANTIC_KEEP_LIMIT=240
# MEMORY_PROMPT_SEMANTIC_LIMIT=24
# MEMORY_MESO_GROUP_SIZE=4
# MEMORY_MACRO_GROUP_SIZE=3
# MEMORY_PROMPT_MESO_LIMIT=4
# MEMORY_PROMPT_MACRO_LIMIT=3
# MEMORY_CONFLICT_KEEP_LIMIT=160
# MEMORY_PROMPT_CONFLICT_LIMIT=14

# Conversation coordinator guardrails
# MODERATOR_INTERVAL=6
# MAX_GENERATION_MS=30000
# MAX_REPETITION_STREAK=2

# Quality optimizer (auto-retry weak turns)
# QUALITY_MIN_WORDS=9
# QUALITY_RETRY_LIMIT=1
# QUALITY_MAX_SIMILARITY=0.9
# QUALITY_MIN_TOPIC_COVERAGE=0.12

# Continuous evaluator loop (novelty/coherence/non-repetition/evidence)
# EVALUATOR_LOOP_ENABLED=true
# EVALUATOR_RETRY_LIMIT=1
# EVALUATOR_MIN_OVERALL=0.56
# EVALUATOR_MIN_NOVELTY=0.22
# EVALUATOR_MIN_COHERENCE=0.26
# EVALUATOR_MIN_EVIDENCE=0.24

# Citation-backed retrieval (debate mode)
# CITATION_RETRIEVAL_ENABLED=true
# CITATION_MAX_REFERENCES=4
# CITATION_REFRESH_INTERVAL=3
# CITATION_TIMEOUT_MS=4500
# CITATION_MIN_REFERENCE_CONFIDENCE=0.18

# Security and deployment hardening
# TRUST_PROXY=false
# APP_ORIGIN=https://openllmchat.example
# CSRF_PROTECTION=true
# CSRF_ALLOWED_ORIGINS=https://admin.openllmchat.example
# API_WRITE_TOKEN=

PORT=3000
